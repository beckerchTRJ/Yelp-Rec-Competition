# ğŸ† Yelp Rating Prediction â€“ 1st Place (USC DSCI 553 Spring 2025)

This project placed **1st out of 110 students** in the USC DSCI 553 Spring 2025 course competition. The goal was to build a high-accuracy recommendation system using the Yelp dataset and Spark RDD, under academic and platform constraints (e.g., no DataFrames, limited libraries, memory/time limits).

---

## ğŸ“š Overview

The objective was to predict star ratings for (user, business) pairs in a large, filtered Yelp dataset using a custom recommendation system. Unlike traditional collaborative filtering models, this solution relied on **robust content-based techniques**, engineered features, and performance-tuned processing in Spark RDD.

---

## ğŸ” Method Summary

The final method evolved from a baseline content-based model in Homework 3 and introduced:

- ğŸ”¬ **Extensive Feature Engineering**:
  - Business metadata (stars, attributes, categories)
  - SVD on business categories
  - Check-in, tip, and photo counts
  - Geolocation features (city, state, lat/lon)
  - **Pseudo-user profiles** derived from averages of visited business attributes

- ğŸ§¹ **Feature Selection**:
  - Generated a large feature set, followed by **backward elimination** to remove noise
  - Notably, user-centric models **degraded** performance, including:
    - Item-based collaborative filtering
    - Matrix factorization
    - User bias metrics

- ğŸ§  **Model Performance**:
  - Locally, **CATBoost** achieved an RMSE of ~0.9708 but was not compatible with the submission environment.
  - Final submitted model used a lightweight, RDD-compatible structure while retaining core feature strategies.

---

## ğŸ“ˆ Results (Validation Set)

- âœ… **Final RMSE**: `0.9747`
- â±ï¸ **Execution Time**: `20.18 seconds`

### ğŸ“Š Error Distribution

| Error Range   | Count     |
|---------------|-----------|
| 0 â‰¤ error < 1 | 102,567   |
| 1 â‰¤ error < 2 | 32,560    |
| 2 â‰¤ error < 3 | 6,107     |
| 3 â‰¤ error < 4 | 808       |
| â‰¥ 4           | 2         |

---

## âš™ï¸ Technologies & Constraints

- Python 3.6.8
- Spark 3.1.2 (**RDD-only**)
- NumPy, Scikit-learn (no CATBoost on Vocareum)
- Deployed under strict academic constraints (no pretraining, no external datasets
- With more time, fewer computational constraints, and wider access to libraries, my end solution would likely have looked different. I was able to obtain stronger performance locally with the usage of a wider array of features and LightGBM, but this was not feasible in the final submission
---

## â–¶ï¸ How to Run

Run this command on the Vocareum platform or compatible Spark 3.1.2 setup:

```bash
/opt/spark/spark-3.1.2-bin-hadoop3.2/bin/spark-submit competition.py <folder_path> <test_file_name> <output_file_name>
